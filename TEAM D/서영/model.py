import torch
import torch.nn as nn
from tqdm import trange 

learning_rate = 0.001

import torch.nn as nn

def conv_2_block(in_dim, out_dim):
    """
    2개의 컨볼루션 레이어와 1개의 맥스 풀링 레이어로 구성된 블록을 생성하는 함수.
    
    Args:
        in_dim (int): 입력 채널 개수
        out_dim (int): 출력 채널 개수
    
    Returns:
        nn.Sequential: 컨볼루션 블록 (Conv2D x 2 + ReLU x 2 + MaxPool2D)
    """
    model = nn.Sequential(
        nn.Conv2d(in_dim, out_dim, kernel_size=3, padding=1),  # 3x3 컨볼루션, 패딩 1
        nn.ReLU(),  # 활성화 함수 (ReLU)
        nn.Conv2d(out_dim, out_dim, kernel_size=3, padding=1),  # 또 다른 3x3 컨볼루션
        nn.ReLU(),  # 활성화 함수 (ReLU)
        nn.MaxPool2d(kernel_size=2, stride=2)  # 2x2 맥스 풀링 (다운샘플링)
    )
    return model

def conv_3_block(in_dim, out_dim):
    """
    3개의 컨볼루션 레이어와 1개의 맥스 풀링 레이어로 구성된 블록을 생성하는 함수.
    
    """
    model = nn.Sequential(
        nn.Conv2d(in_dim, out_dim, kernel_size=3, padding=1),  # 첫 번째 3x3 컨볼루션, 입력 채널 -> 출력 채널
        nn.ReLU(),  # 활성화 함수 (ReLU)
        nn.Conv2d(out_dim, out_dim, kernel_size=3, padding=1),  # 두 번째 3x3 컨볼루션, 출력 채널 유지
        nn.ReLU(),  # 활성화 함수 (ReLU)
        nn.Conv2d(out_dim, out_dim, kernel_size=3, padding=1),  # 세 번째 3x3 컨볼루션, 출력 채널 유지
        nn.ReLU(),  # 활성화 함수 (ReLU)
        nn.MaxPool2d(kernel_size=2, stride=2)  # 2x2 맥스 풀링 (특성 맵 크기 절반 축소)
    )
    return model

class VGG(nn.Module):
    """
    VGG 모델을 구현한 클래스.
    
    Args:
        base_dim (int): 기본 채널 개수 (64부터 시작)
        num_classes (int): 분류할 클래스 개수 (기본값: 10, CIFAR-10)
    """
    def __init__(self, base_dim, num_classes=10):
        super(VGG, self).__init__()
        self.feature = nn.Sequential(
            conv_2_block(3, base_dim),         # 입력(3채널) -> 64채널 (Conv2D x2 + MaxPool)
            conv_2_block(base_dim, 2*base_dim), # 64채널 -> 128채널 (Conv2D x2 + MaxPool)
            conv_3_block(2*base_dim, 4*base_dim), # 128채널 -> 256채널 (Conv2D x3 + MaxPool)
            conv_3_block(4*base_dim, 8*base_dim), # 256채널 -> 512채널 (Conv2D x3 + MaxPool)
            conv_3_block(8*base_dim, 8*base_dim), # 512채널 -> 512채널 (Conv2D x3 + MaxPool)
        )
        
        self.fc_layer = nn.Sequential(
            # CIFAR-10은 입력 이미지 크기가 32x32이므로 1x1 feature map 사용
            nn.Linear(8*base_dim*1*1, 4096),  # 512 -> 4096 Fully Connected Layer
            # IMAGENET의 경우 입력 크기가 224x224이므로 아래를 사용해야 함
            # nn.Linear(8*base_dim*7*7, 4096),
            nn.ReLU(True),
            nn.Dropout(),
            nn.Linear(4096, 1000),  # 4096 -> 1000 Fully Connected Layer
            nn.ReLU(True),
            nn.Dropout(),
            nn.Linear(1000, num_classes),  # 1000 -> num_classes Fully Connected Layer
        )

    def forward(self, x):
        """
        순전파 함수.
        
        Args:
            x (Tensor): 입력 이미지 텐서
        
        Returns:
            Tensor: 분류 결과
        """
        x = self.feature(x)  # 특징 추출
        x = x.view(x.size(0), -1)  # Fully Connected Layer에 입력을 위해 Flatten 처리
        x = self.fc_layer(x)  # 분류 진행
        return x

# -*- coding: utf-8 -*-
"""architecture_change

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dfuQ5mhJu-_Sqc8bgkvfzIGZhTiMsCbN

# 1. 레이어 구성 변경
"""

import torch.nn as nn

# 간단한 VGG 구조: conv_2_block만 사용하고 블록 수를 줄임
class VGG_Simple(nn.Module):
    def __init__(self, base_dim=64, num_classes=10):
        super(VGG_Simple, self).__init__()
        self.feature = nn.Sequential(
            conv_2_block(3, base_dim),  # 입력 3채널 -> base_dim
            conv_2_block(base_dim, base_dim * 2),  # 채널 수 2배 증가
            conv_2_block(base_dim * 2, base_dim * 4)  # 총 3블록만 사용
        )
        self.fc_layer = nn.Sequential(
            nn.Linear(base_dim * 4 * 4 * 4, 512),  # CIFAR-10은 32x32 → 4x4로 줄어듦
            nn.ReLU(),
            nn.Dropout(),
            nn.Linear(512, num_classes)
        )

    def forward(self, x):
        x = self.feature(x)
        x = x.view(x.size(0), -1)  # Flatten
        x = self.fc_layer(x)
        return x

"""- 기존 VGG보다 **얕은 구조**
- `conv_2_block`만 사용하며 블록 수를 3개로 제한
- Fully Connected Layer도 간단히 구성
- CIFAR-10과 같이 입력 크기가 작은 데이터셋에 적합

#  2. BatchNorm 추가된 VGG
"""

# BatchNorm이 들어간 conv_2_block 정의
def conv_2_block_bn(in_dim, out_dim):
    return nn.Sequential(
        nn.Conv2d(in_dim, out_dim, kernel_size=3, padding=1),
        nn.BatchNorm2d(out_dim),  # 배치 정규화 추가
        nn.ReLU(),
        nn.Conv2d(out_dim, out_dim, kernel_size=3, padding=1),
        nn.BatchNorm2d(out_dim),  # 배치 정규화 추가
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2, stride=2)
    )

# BatchNorm이 포함된 VGG 구조
class VGG_BatchNorm(nn.Module):
    def __init__(self, base_dim=64, num_classes=10):
        super(VGG_BatchNorm, self).__init__()
        self.feature = nn.Sequential(
            conv_2_block_bn(3, base_dim),
            conv_2_block_bn(base_dim, base_dim * 2),
            conv_2_block_bn(base_dim * 2, base_dim * 4)
        )
        self.fc_layer = nn.Sequential(
            nn.Linear(base_dim * 4 * 4 * 4, 512),
            nn.ReLU(),
            nn.Dropout(),
            nn.Linear(512, num_classes)
        )

    def forward(self, x):
        x = self.feature(x)
        x = x.view(x.size(0), -1)
        x = self.fc_layer(x)
        return x

"""- 기존 VGG 구조를 간소화하면서 **Batch Normalization**을 적용한 CNN 모델
- 배치 정규화를 통해 학습 안정성 향상 및 수렴 속도 증가
- CIFAR-10과 같은 소형 이미지 데이터셋에 적합한 구조

# 3. Dropout 추가 (Convolution 사이에)
"""

# Conv 레이어 사이에 Dropout 삽입
def conv_2_block_dropout(in_dim, out_dim):
    return nn.Sequential(
        nn.Conv2d(in_dim, out_dim, kernel_size=3, padding=1),
        nn.ReLU(),
        nn.Dropout(0.2),  # 20% 확률로 뉴런 무시
        nn.Conv2d(out_dim, out_dim, kernel_size=3, padding=1),
        nn.ReLU(),
        nn.Dropout(0.2),
        nn.MaxPool2d(kernel_size=2, stride=2)
    )

# Dropout이 포함된 VGG 구조
class VGG_Dropout(nn.Module):
    def __init__(self, base_dim=64, num_classes=10):
        super(VGG_Dropout, self).__init__()
        self.feature = nn.Sequential(
            conv_2_block_dropout(3, base_dim),
            conv_2_block_dropout(base_dim, base_dim * 2),
            conv_2_block_dropout(base_dim * 2, base_dim * 4)
        )
        self.fc_layer = nn.Sequential(
            nn.Linear(base_dim * 4 * 4 * 4, 512),
            nn.ReLU(),
            nn.Dropout(0.5),  # FC에서도 Dropout 적용
            nn.Linear(512, num_classes)
        )

    def forward(self, x):
        x = self.feature(x)
        x = x.view(x.size(0), -1)
        x = self.fc_layer(x)
        return x

"""- 기존 VGG 구조를 간소화하면서 **Dropout을 Convolution 사이에도 삽입**
- 특징 추출 과정에서의 과적합 방지를 강화한 구조
- CIFAR-10처럼 이미지가 작고 데이터 수가 적을 때 과적합 방지에 효과적

# 4. ReLU → LeakyReLU 변경
"""

# LeakyReLU 사용한 Conv 블록
def conv_2_block_leaky(in_dim, out_dim):
    return nn.Sequential(
        nn.Conv2d(in_dim, out_dim, kernel_size=3, padding=1),
        nn.LeakyReLU(0.1),  # ReLU 대신 LeakyReLU
        nn.Conv2d(out_dim, out_dim, kernel_size=3, padding=1),
        nn.LeakyReLU(0.1),
        nn.MaxPool2d(kernel_size=2, stride=2)
    )

# LeakyReLU가 포함된 VGG 구조
class VGG_Leaky(nn.Module):
    def __init__(self, base_dim=64, num_classes=10):
        super(VGG_Leaky, self).__init__()
        self.feature = nn.Sequential(
            conv_2_block_leaky(3, base_dim),
            conv_2_block_leaky(base_dim, base_dim * 2),
            conv_2_block_leaky(base_dim * 2, base_dim * 4)
        )
        self.fc_layer = nn.Sequential(
            nn.Linear(base_dim * 4 * 4 * 4, 512),
            nn.LeakyReLU(0.1),
            nn.Dropout(),
            nn.Linear(512, num_classes)
        )

    def forward(self, x):
        x = self.feature(x)
        x = x.view(x.size(0), -1)
        x = self.fc_layer(x)
        return x

"""- 일반적인 ReLU 대신 **LeakyReLU**를 사용한 VGG 구조
- ReLU의 문제점인 "죽은 뉴런"을 방지하며 **더 안정적인 학습 가능**
- CIFAR-10처럼 작은 이미지 데이터셋에 적용하기 좋은 가벼운 구조

# 5. Global Average Pooling 사용
"""

# GAP (Global Average Pooling) 적용 버전
class VGG_GAP(nn.Module):
    def __init__(self, base_dim=64, num_classes=10):
        super(VGG_GAP, self).__init__()
        self.feature = nn.Sequential(
            conv_2_block(3, base_dim),
            conv_2_block(base_dim, base_dim * 2),
            conv_2_block(base_dim * 2, base_dim * 4)
        )
        self.pool = nn.AdaptiveAvgPool2d((1, 1))  # Feature map → 1x1으로 줄임
        self.classifier = nn.Linear(base_dim * 4, num_classes)  # FC 대신 간단한 분류

    def forward(self, x):
        x = self.feature(x)
        x = self.pool(x)  # GAP
        x = x.view(x.size(0), -1)
        x = self.classifier(x)
        return x

"""- 기존 VGG 구조에서 Fully Connected Layer 대신 **Global Average Pooling (GAP)** 사용
- FC 파라미터 수를 크게 줄여서 모델 경량화 및 과적합 감소에 도움
- CIFAR-10과 같은 소형 이미지 분류에 적합
"""




