import os
import torch
from PIL import Image
import torchvision.transforms as transforms
from vgg16 import VGG16 as VGG16_Original
from vgg16_light import VGG16 as VGG16_Light
from torchvision import datasets
import matplotlib.pyplot as plt
import torch.nn.functional as F
import time

# Device ì„¤ì •
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# CIFAR-10 í´ë˜ìŠ¤ ëª©ë¡
cifar10_test = datasets.CIFAR10(root="./Data/", train=False, download=True)
class_names = cifar10_test.classes

# ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì •ì˜
transform = transforms.Compose([
    transforms.Resize((32, 32)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

# ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜
def load_model(model_class, path):
    model = model_class(base_dim=64).to(device)
    model.load_state_dict(torch.load(path, map_location=device))
    model.eval()
    return model

model_orig = load_model(VGG16_Original, "./train_model")
model_light = load_model(VGG16_Light, "./train_model_light")

# ì´ë¯¸ì§€ í´ë” ê²½ë¡œ
image_dir = os.path.join(os.path.dirname(__file__), 'dog')
image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]

# ìë™ ë°˜ë³µ ì˜ˆì¸¡ ë° ì‹œê°í™”
with torch.no_grad():
    for image_name in image_files:
        image_path = os.path.join(image_dir, image_name)
        image_pil = Image.open(image_path).convert('RGB')
        image_tensor = transform(image_pil).unsqueeze(0).to(device)

        # ì›ë³¸ VGG ì˜ˆì¸¡
        start = time.time()
        output_orig = model_orig(image_tensor)
        time_orig = time.time() - start
        _, pred_orig = torch.max(output_orig, 1)
        class_orig = class_names[pred_orig.item()]
        prob_orig = F.softmax(output_orig, dim=1)
        confidence_orig = prob_orig.max().item()

        # ê²½ëŸ‰ VGG ì˜ˆì¸¡
        start = time.time()
        output_light = model_light(image_tensor)
        time_light = time.time() - start
        _, pred_light = torch.max(output_light, 1)
        class_light = class_names[pred_light.item()]
        prob_light = F.softmax(output_light, dim=1)
        confidence_light = prob_light.max().item()

        print(f"[{image_name}]")
        print(f" âœ… Original VGG â–¸ {class_orig} (ì˜ˆì¸¡ í™•ë¥ : {confidence_orig*100:.2f}%, ì‹œê°„: {time_orig*1000:.1f}ms)")
        print(f" ğŸ”¹ Light VGG    â–¸ {class_light} (ì˜ˆì¸¡ í™•ë¥ : {confidence_light*100:.2f}%, ì‹œê°„: {time_light*1000:.1f}ms)")

        # ì‹œê°í™” ì¶œë ¥
        plt.imshow(image_pil)
        plt.title(f"Original: {class_orig} | Light: {class_light}")
        plt.axis('off')
        plt.show()
