# -*- coding: utf-8 -*-
"""vgg_architecture1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1d5XTdVCJxsSqjdFr_1aRc5K4ZG8jOGnP
"""

import torch  # PyTorch 라이브러리
import torch.nn as nn  # torch.nn: 신경망 모듈
import torch.optim as optim  # torch.optim: 최적화 알고리즘
import torchvision  # torchvision: 이미지 데이터 처리
import torchvision.datasets as datasets  # datasets: 데이터셋 불러오기
import torchvision.transforms as transforms  # transforms: 이미지 변환
from torch.utils.data import DataLoader  # DataLoader: 데이터 로딩
import matplotlib.pyplot as plt  # matplotlib: 그래프 시각화
import numpy as np  # numpy: 숫자 계산
from tqdm import tqdm  # tqdm: 진행상황 안내

def conv_2_block(in_dim, out_dim):
    return nn.Sequential(
        nn.Conv2d(in_dim, out_dim, kernel_size=3, padding=1),
        nn.ReLU(),
        nn.Conv2d(out_dim, out_dim, kernel_size=3, padding=1),
        nn.ReLU(),
        nn.MaxPool2d(2, 2)
    )

def conv_3_block(in_dim, out_dim):
    return nn.Sequential(
        nn.Conv2d(in_dim, out_dim, kernel_size=3, padding=1),
        nn.ReLU(),
        nn.Conv2d(out_dim, out_dim, kernel_size=3, padding=1),
        nn.ReLU(),
        nn.Conv2d(out_dim, out_dim, kernel_size=3, padding=1),
        nn.ReLU(),
        nn.MaxPool2d(2, 2)
    )



"""# VGG_B: base_dim의 크기 32로 변경

base_dim: 첫 번째 합성곱 층(Conv Layer)의 필터 개수</p>
과적합 방지, 연산량 감소 </p>
but 피처 추출량 역시 감소
"""

class VGG_B(nn.Module):
    def __init__(self, base_dim=32, num_classes=10):  # base_dim 감소
        super(VGG_B, self).__init__()
        self.feature = nn.Sequential(
            conv_2_block(3, base_dim),                # 3 → 32
            conv_2_block(base_dim, base_dim * 2),     # 32 → 64
            conv_3_block(base_dim * 2, base_dim * 4), # 64 → 128
            conv_3_block(base_dim * 4, base_dim * 8), # 128 → 256
            conv_3_block(base_dim * 8, base_dim * 8)
        )
        self.fc_layer = nn.Sequential(
            nn.Linear(base_dim * 8 * 1 * 1, 4096),
            nn.ReLU(True),
            nn.Dropout(),
            nn.Linear(4096, 1000),
            nn.ReLU(True),
            nn.Dropout(),
            nn.Linear(1000, num_classes)
        )

    def forward(self, x):
        x = self.feature(x)
        x = x.view(x.size(0), -1)
        x = self.fc_layer(x)
        return x

# 하이퍼파라미터
batch_size = 100
learning_rate = 0.0002
num_epoch = 5

# 데이터셋
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

trainset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)
testset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)
train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False)

# 모델 학습
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = VGG_B().to(device)
loss_func = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

loss_arr = []
for epoch in range(num_epoch):
    total_loss = 0
    model.train()
    for images, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epoch}"):
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = loss_func(outputs, labels)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    avg_loss = total_loss / len(train_loader)
    loss_arr.append(avg_loss)
    print(f"Epoch {epoch+1}, Loss: {avg_loss:.4f}")

# 손실 시각화
plt.plot(loss_arr)
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("VGG_B Training Loss")
plt.show()

# 모델 평가
model.eval()
correct = 0
total = 0
with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
accuracy = 100 * correct / total
print(f"Test Accuracy: {accuracy:.2f}%")

"""학습속도가 훨씬 빨라짐

base_dim을 2배로 늘렸을 땐 한 epoch 당 2시간 55분이 걸려서 포기

=========================================================================================================

# VGG_C: 층 수 증가 (block 수 동일, conv 개수 증가)

conv_2_block → conv_3_block_deep: 더 깊고 복잡한 특징을 뽑아내게 함\
but 연산량 증가, 과적합 위험\
\
실제로 test 값 성능 10%로 감소
"""

def conv_3_block_deep(in_dim, out_dim):
    return nn.Sequential(
        nn.Conv2d(in_dim, out_dim, kernel_size=3, padding=1),
        nn.ReLU(),
        nn.Conv2d(out_dim, out_dim, kernel_size=3, padding=1),
        nn.ReLU(),
        nn.Conv2d(out_dim, out_dim, kernel_size=3, padding=1),
        nn.ReLU(),
        nn.Conv2d(out_dim, out_dim, kernel_size=3, padding=1),
        nn.ReLU(),
        nn.MaxPool2d(2, 2)
    )

class VGG_C(nn.Module):
    def __init__(self, base_dim=64, num_classes=10):
        super(VGG_C, self).__init__()
        self.feature = nn.Sequential(                                            # 변경점
            conv_3_block_deep(3, base_dim),
            conv_3_block_deep(base_dim, base_dim * 2),
            conv_3_block_deep(base_dim * 2, base_dim * 4),
            conv_3_block_deep(base_dim * 4, base_dim * 8),
            conv_3_block_deep(base_dim * 8, base_dim * 8)
        )
        self.fc_layer = nn.Sequential(
            nn.Linear(base_dim * 8 * 1 * 1, 4096),
            nn.ReLU(True),
            nn.Dropout(),
            nn.Linear(4096, 1000),
            nn.ReLU(True),
            nn.Dropout(),
            nn.Linear(1000, num_classes)
        )

    def forward(self, x):
        x = self.feature(x)
        x = x.view(x.size(0), -1)
        x = self.fc_layer(x)
        return x

batch_size = 100
learning_rate = 0.0002
num_epoch = 5

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

trainset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)
testset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)
train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = VGG_C().to(device)
loss_func = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

loss_arr = []
for epoch in range(num_epoch):
    total_loss = 0
    model.train()
    for images, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epoch}"):
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = loss_func(outputs, labels)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    avg_loss = total_loss / len(train_loader)
    loss_arr.append(avg_loss)
    print(f"Epoch {epoch+1}, Loss: {avg_loss:.4f}")

plt.plot(loss_arr)
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("VGG_C Training Loss")
plt.show()

model.eval()
correct = 0
total = 0
with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
accuracy = 100 * correct / total
print(f"Test Accuracy: {accuracy:.2f}%")

"""=========================================================================================================

# VGG_F: FC layer 제거, 대신 Global Average Pooling 사용

모델을 간결하고 일반화에 강하게
"""

def conv_block(in_dim, out_dim):
    return nn.Sequential(
        nn.Conv2d(in_dim, out_dim, kernel_size=3, padding=1),
        nn.ReLU(),
        nn.Conv2d(out_dim, out_dim, kernel_size=3, padding=1),
        nn.ReLU(),
        nn.MaxPool2d(2, 2)
    )

class VGG_F(nn.Module):
    def __init__(self, base_dim=64, num_classes=10):
        super(VGG_F, self).__init__()
        self.feature = nn.Sequential(
            conv_block(3, base_dim),
            conv_block(base_dim, base_dim * 2),
            conv_block(base_dim * 2, base_dim * 4),
            conv_block(base_dim * 4, base_dim * 8),
            conv_block(base_dim * 8, base_dim * 8),
            nn.AdaptiveAvgPool2d((1, 1))  # Global Average Pooling
        )
        self.classifier = nn.Linear(base_dim * 8, num_classes)

    def forward(self, x):
        x = self.feature(x)
        x = x.view(x.size(0), -1)
        x = self.classifier(x)
        return x

batch_size = 100
learning_rate = 0.0002
num_epoch = 5

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

trainset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)
testset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)
train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = VGG_F().to(device)
loss_func = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

loss_arr = []
for epoch in range(num_epoch):
    total_loss = 0
    model.train()
    for images, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epoch}"):
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = loss_func(outputs, labels)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    avg_loss = total_loss / len(train_loader)
    loss_arr.append(avg_loss)
    print(f"Epoch {epoch+1}, Loss: {avg_loss:.4f}")

plt.plot(loss_arr)
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("VGG_F Training Loss")
plt.show()

model.eval()
correct = 0
total = 0
with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
accuracy = 100 * correct / total
print(f"Test Accuracy: {accuracy:.2f}%")



"""# VGG_D: MaxPool → AvgPool 변경
## 기존 구조에서 모든 MaxPool2d를 AvgPool2d로 바꿔서 평균 풀링으로 다운샘플링

MaxPool: 강한 특징(예: Edge, Texture, Object Boundary 등) 강조

AvgPool: 전체적인 특징 고려 → but 특징이 희석될 수 있음
"""

def conv_2_block(in_dim, out_dim):
    return nn.Sequential(
        nn.Conv2d(in_dim, out_dim, kernel_size=3, padding=1),
        nn.ReLU(),
        nn.Conv2d(out_dim, out_dim, kernel_size=3, padding=1),
        nn.ReLU(),
        nn.AvgPool2d(2, 2)  # 평균 풀링으로 변경
    )

def conv_3_block(in_dim, out_dim):
    return nn.Sequential(
        nn.Conv2d(in_dim, out_dim, kernel_size=3, padding=1),
        nn.ReLU(),
        nn.Conv2d(out_dim, out_dim, kernel_size=3, padding=1),
        nn.ReLU(),
        nn.Conv2d(out_dim, out_dim, kernel_size=3, padding=1),
        nn.ReLU(),
        nn.AvgPool2d(2, 2)  # 평균 풀링으로 변경
    )

class VGG_D(nn.Module):
    def __init__(self, base_dim=64, num_classes=10):
        super(VGG_D, self).__init__()
        self.feature = nn.Sequential(
            conv_2_block(3, base_dim),
            conv_2_block(base_dim, base_dim * 2),
            conv_3_block(base_dim * 2, base_dim * 4),
            conv_3_block(base_dim * 4, base_dim * 8),
            conv_3_block(base_dim * 8, base_dim * 8)
        )
        self.fc_layer = nn.Sequential(
            nn.Linear(base_dim * 8 * 1 * 1, 4096),
            nn.ReLU(True),
            nn.Dropout(),
            nn.Linear(4096, 1000),
            nn.ReLU(True),
            nn.Dropout(),
            nn.Linear(1000, num_classes)
        )

    def forward(self, x):
        x = self.feature(x)
        x = x.view(x.size(0), -1)
        x = self.fc_layer(x)
        return x

batch_size = 100
learning_rate = 0.0002
num_epoch = 5

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

trainset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)
testset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)
train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = VGG_D().to(device)
loss_func = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

loss_arr = []
for epoch in range(num_epoch):
    total_loss = 0
    model.train()
    for images, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epoch}"):
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = loss_func(outputs, labels)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    avg_loss = total_loss / len(train_loader)
    loss_arr.append(avg_loss)
    print(f"Epoch {epoch+1}, Loss: {avg_loss:.4f}")

plt.plot(loss_arr)
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("VGG_D Training Loss")
plt.show()

model.eval()
correct = 0
total = 0
with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
accuracy = 100 * correct / total
print(f"Test Accuracy: {accuracy:.2f}%")

"""# VGG_E: 5x5 커널 사용 (conv layer의 kernel_size = 5, padding=2)"""

def conv_2_block(in_dim, out_dim):
    return nn.Sequential(
        nn.Conv2d(in_dim, out_dim, kernel_size=5, padding=2),
        nn.ReLU(),
        nn.Conv2d(out_dim, out_dim, kernel_size=5, padding=2),
        nn.ReLU(),
        nn.MaxPool2d(2, 2)
    )

def conv_3_block(in_dim, out_dim):
    return nn.Sequential(
        nn.Conv2d(in_dim, out_dim, kernel_size=5, padding=2),
        nn.ReLU(),
        nn.Conv2d(out_dim, out_dim, kernel_size=5, padding=2),
        nn.ReLU(),
        nn.Conv2d(out_dim, out_dim, kernel_size=5, padding=2),
        nn.ReLU(),
        nn.MaxPool2d(2, 2)
    )

class VGG_E(nn.Module):
    def __init__(self, base_dim=64, num_classes=10):
        super(VGG_E, self).__init__()
        self.feature = nn.Sequential(
            conv_2_block(3, base_dim),
            conv_2_block(base_dim, base_dim * 2),
            conv_3_block(base_dim * 2, base_dim * 4),
            conv_3_block(base_dim * 4, base_dim * 8),
            conv_3_block(base_dim * 8, base_dim * 8)
        )
        self.fc_layer = nn.Sequential(
            nn.Linear(base_dim * 8 * 1 * 1, 4096),
            nn.ReLU(True),
            nn.Dropout(),
            nn.Linear(4096, 1000),
            nn.ReLU(True),
            nn.Dropout(),
            nn.Linear(1000, num_classes)
        )

    def forward(self, x):
        x = self.feature(x)
        x = x.view(x.size(0), -1)
        x = self.fc_layer(x)
        return x

batch_size = 100
learning_rate = 0.0002
num_epoch = 5

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

trainset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)
testset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)
train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = VGG_E().to(device)
loss_func = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

loss_arr = []
for epoch in range(num_epoch):
    total_loss = 0
    model.train()
    for images, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epoch}"):
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = loss_func(outputs, labels)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    avg_loss = total_loss / len(train_loader)
    loss_arr.append(avg_loss)
    print(f"Epoch {epoch+1}, Loss: {avg_loss:.4f}")

plt.plot(loss_arr)
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("VGG_E Training Loss")
plt.show()

model.eval()
correct = 0
total = 0
with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
accuracy = 100 * correct / total
print(f"Test Accuracy: {accuracy:.2f}%")

